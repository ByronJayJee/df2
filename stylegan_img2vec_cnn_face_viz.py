# -*- coding: utf-8 -*-
"""StyleGan - Img2Vec CNN Face Viz

Modified from code automatically generated by Colaboratory.
"""

import os
import numpy as np
import random
import sys
import pickle
# Load PIL
from PIL import Image

from matplotlib import pyplot as plt
import pandas as pd

from keras.layers import Conv2D, MaxPooling2D, Input, Dense, Flatten, Dropout
from keras.models import Model
from keras.preprocessing import image
from keras.layers import GlobalMaxPooling2D
from keras.callbacks import ModelCheckpoint


from keras.preprocessing.image import ImageDataGenerator
from keras.callbacks import ModelCheckpoint, CSVLogger

from keras.models import load_model

from PIL import Image
from PIL import ImageFont
from PIL import ImageDraw


def read_reg_img(filename, size=(1024, 1024)):
   im_reg = Image.open(filename)
   im_reg.thumbnail(size)
   return im_reg

def plot_training_history_with_point(idx_epoch):
    #idx_epoch=10
    
    plt.figure(figsize=(10,5))
    plt.rcParams.update({'font.size': 16})
    plt.plot(df_history['epoch']+1,df_history['loss'])
    plt.plot(df_history['epoch'][idx_epoch:idx_epoch+1]+1,df_history['loss'][idx_epoch:idx_epoch+1], marker='o', markersize=6, color="red")
    plt.yscale('log')
    #plt.title('Model loss')
    plt.ylabel('Model Loss')
    plt.xlabel('Model Training Epoch')
    plt.grid(True)
    
    
    tmp_fout = f"plot_img/bjg_gen_plot_{idx_epoch+1:04d}.png"
    print(tmp_fout)
    plt.savefig(tmp_fout)
    #plt.show()
    plt.close()
	
def face_plot_training_history_with_point(idx_epoch):
    #idx_epoch=0

    img_pixel_size=224
    
    tmp_gen_fname = f"test_img/bjg_gen_{idx_epoch+1:04d}.jpg"
    tmp_plot_fname = f"plot_img/bjg_gen_plot_{idx_epoch+1:04d}.png"

    im_gen = read_reg_img(tmp_gen_fname, size=(img_pixel_size, img_pixel_size))
    im_plot = read_reg_img(tmp_plot_fname, size=(img_pixel_size*2, img_pixel_size*2))

    total_width = img_pixel_size*2
    max_height = img_pixel_size*2

    x_offset=img_pixel_size

    new_im = Image.new('RGB', (total_width, max_height))

    new_im.paste(bjg_headshot, (0,0))
    new_im.paste(im_gen, (x_offset,0))
    new_im.paste(im_plot, (0,x_offset))
    
    tmp_fout = f"face_hist_plot_img/bjg_gen_hist_plot_{idx_epoch+1:04d}.png"
    print(tmp_fout)

    new_im.save(tmp_fout)

bjg_headshot = read_reg_img('../../../../BJG_Headshots/Byron-btw18-headshot.jpg', size=(224, 224))

bjg_arr = np.array(bjg_headshot)
bjg_arr.shape
bjg_pred_vec = conv_model.predict(np.array([bjg_arr]))
bjg_pred_vec[0]

""" need to remove dependence on tflib! 'convert_images_to_uint8' can be replaced by one line """
""" need to remove dependence on tflib! tflib.init_tf really just does a tf create_session """

fmt = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True)

# Initialize TensorFlow.
tflib.init_tf()

filename = '../../../stylegan/models/karras2019stylegan-ffhq-1024x1024.pkl'

infile = open(filename,'rb')
_G, _D, Gs = pickle.load(infile)
infile.close()

bjg_image_pred = Gs.run(bjg_pred_vec, None, randomize_noise=False, output_transform=fmt, dlatent_avg_beta=None, style_mixing_prob=None, truncation_psi= None,truncation_cutoff= None)

bjg_image_pred[0].shape
bjg_deepfake_img_pred = Image.fromarray(bjg_image_pred[0], 'RGB')


all_frames = []
for idx in range(15):
    filename = f"model_checkpoints/conv_weights_loss_logger.{idx+1:04d}.hdf5"
    print(filename)
    #tmp_conv_model = load_model('./model_checkpoints/conv_weights_loss_logger.0050.hdf5')
    tmp_conv_model = load_model(filename)
    tmp_bjg_pred_vec = tmp_conv_model.predict(np.array([bjg_arr]))
    tmp_bjg_image_pred = Gs.run(tmp_bjg_pred_vec, None, randomize_noise=False, output_transform=fmt, dlatent_avg_beta=None, style_mixing_prob=None, truncation_psi= None,truncation_cutoff= None)
    tmp_bjg_deepfake_img_pred = Image.fromarray(tmp_bjg_image_pred[0], 'RGB')
    tmp_bjg_deepfake_img_pred.thumbnail((224,224))
    draw = ImageDraw.Draw(tmp_bjg_deepfake_img_pred)
    # font = ImageFont.truetype(<font-file>, <font-size>)
    #font = ImageFont.truetype("sans-serif.ttf", 16)
    # draw.text((x, y),"Sample Text",(r,g,b))
    #draw.text((0, 0),"Sample Text",(255,255,255),font=font)
    tmp_txt = "Iteration: %03d" % (idx+1)
    #tmp_txt = "Iteration:"
    #draw.text((100, 0),"Sample Text",(255,255,255))
    draw.rectangle((125-2,0,125+85, 0+10),fill='black')
    draw.text((125, 0),tmp_txt,(255,255,255))
    all_frames.append(tmp_bjg_deepfake_img_pred)
    tmp_fout = f"test_img/bjg_gen_{idx+1:04d}.jpg"
    tmp_bjg_deepfake_img_pred.save(tmp_fout)

# Save into a GIF file that loops forever
gif_time = len(all_frames)*200
print(gif_time)
all_frames[0].save('test_350_txt2.gif', format='GIF', append_images=all_frames[1:], save_all=True, duration=gif_time, loop=0)

df_history = pd.read_csv("log_conv_model_training.csv")
df_history.head()

# Let's make error plots to correspond with the face predictions
plot_training_history_with_point(0)

for idx in range(350):
    plot_training_history_with_point(idx)

# Let's combine headshot, generated faces, and error plots 
bjg_headshot = read_reg_img('../../../../BJG_Headshots/Byron-btw18-headshot.jpg', size=(224, 224))

face_plot_training_history_with_point(0)

for idx in range(350):
    face_plot_training_history_with_point(idx)

img_tot = []
for idx in range(350):
    tmp_fout = f"face_hist_plot_img/bjg_gen_hist_plot_{idx+1:04d}.png"
    print(tmp_fout)
    
    img_face_hist = read_reg_img(tmp_fout, (224*2, 224*2))
    img_tot.append(img_face_hist)

# Save into a GIF file that loops forever
gif_time = len(img_tot)*200
print(gif_time)
img_tot[0].save('face_10_hist.gif', format='GIF', append_images=img_tot[1:], save_all=True, duration=250, loop=0)

