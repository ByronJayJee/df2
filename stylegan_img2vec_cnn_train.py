# -*- coding: utf-8 -*-
"""StyleGan - Img2Vec CNN Train

Modified from code automatically generated by Colaboratory.
"""


import os
import numpy as np
import random
# Load PIL
from PIL import Image

from keras.layers import Conv2D, MaxPooling2D, Input, Dense, Flatten, Dropout
from keras.models import Model
from keras.preprocessing import image
from keras.layers import GlobalMaxPooling2D
from keras.callbacks import ModelCheckpoint


from keras.preprocessing.image import ImageDataGenerator
from keras.callbacks import ModelCheckpoint, CSVLogger

def read_reg_img(filename, size=(1024, 1024)):
   im_reg = Image.open(filename)
   im_reg.thumbnail(size)
   return im_reg

# this generator returns a batch of face images and corresponding vectors
def input_gen(batch_size=16):
    while True:
        
        idx_list = random.sample(range(len(path_img)), batch_size)
        
        img_list = []
        vec_list = []
        
        count=0
        for idx in idx_list:
            count = count +1
            print(count)
            #print(idx)
            tmp_img_path = path_img[idx]
            tmp_file_num = os.path.basename(tmp_img_path).split('.')[-2]
            tmp_vec_path = './npy/g_out.' + str(tmp_file_num) + '.npy'
            
            tmp_img = read_reg_img(tmp_img_path, size=(224,224))
            tmp_vec = np.load(tmp_vec_path)
            
            img_list.append(np.array(tmp_img))
            vec_list.append(tmp_vec[0])
            
    
        #print(vec_list)
        yield np.array(img_list), np.array(vec_list)

'''
""" walk though path and get images"""

path_img = []
for (dirpath, dirnames, filenames) in os.walk("."):
    for x in filenames:
        tmp_ext=os.path.basename(x).split('.')[-1]
        tmp_ext_lower = tmp_ext.lower()
        if tmp_ext_lower=='png':
            path_img.append(os.path.join(dirpath, x))
    #f.extend(filenames)
    #f.extend(dirnames)
    #break
print(path_img)
print(len(path_img))

"""now that we have a list of image paths, lets convert that to vector npy file paths"""

tmp_path = path_img[0]
print(tmp_path)

tmp_file_num = os.path.basename(tmp_path).split('.')[-2]
print(tmp_file_num)

new_file_path = './npy/g_out.' + str(tmp_file_num) + '.npy'
print(new_file_path)


""" Lets try reading in the npy file"""

tmp_img_vec = np.load(new_file_path)
print(tmp_img_vec[0])

"""we can read the vector. lets make sure we can read in the image itself"""

test_img = read_reg_img(path_img[0])


# save all images to single image npy file
# save all vecs to single vec npy file
### This makes life easier if we ever need to restart this process later (if so, comment this block of code and uncomment np.load block)
sg_img_list, sg_vec_list = next(input_gen(batch_size=10000))
np.save('sg_img_list.npy', sg_img_list)
np.save('sg_vec_list.npy', sg_vec_list)
'''

sg_img_list = np.load('sg_img_list.npy')
sg_vec_list = np.load('sg_vec_list.npy')

"""We can read our images and vecs. we have a generator. lets get to the neural net!"""
img_input = Input(shape=(224, 224, 3))
x = Conv2D(32, (5, 5))(img_input)
x = MaxPooling2D((2, 2))(x)
x = Dropout(rate=0.1)(x)

x = Conv2D(32, (3, 3))(x)
x = MaxPooling2D((2, 2))(x)
x = Dropout(rate=0.1)(x)

x = Conv2D(32, (3, 3))(x)
x = MaxPooling2D((2, 2))(x)
x = Dropout(rate=0.1)(x)

conv_out = Flatten()(x)

dense_out = Dense(512)(conv_out)

#create graph of new whole model
conv_model = Model(inputs = img_input, outputs = dense_out)

#compile the model
conv_model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_squared_error'])

### print summary of the model architecture
conv_model.summary()

datagen = ImageDataGenerator(
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    vertical_flip=True)

# compute quantities required for featurewise normalization
# (std, mean, and principal components if ZCA whitening is applied)
datagen.fit(sg_img_list)

csv_logger = CSVLogger('conv_model_training.log')

ckpt_conv_callback_no_loss = ModelCheckpoint(filepath='model_checkpoints/conv_weights_loss_logger.{epoch:04d}.hdf5', monitor='loss')

# fits the model on batches with real-time data augmentation:
conv_model_history_logger = conv_model.fit_generator(datagen.flow(sg_img_list, sg_vec_list, batch_size=128),
                    steps_per_epoch=len(sg_img_list) / 128, epochs=2000, callbacks=[ckpt_conv_callback_no_loss, csv_logger])